{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a9c4d01",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85c8030d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Set up Kaggle API\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "debabb3b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d624a5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4: Unzip only the img_align_celeba folder (it takes time, big dataset!)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71bebca1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02e9ec4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CelebADataset:\n",
    "    def __init__(self, folder_path, limit=80000, img_size=128):\n",
    "        self.img_size = img_size\n",
    "        self.folder_path = folder_path\n",
    "        self.file_names = os.listdir(folder_path)[:limit]  # Limit the number of images\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.file_names)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        img_name = self.file_names[idx]\n",
    "        img_path = os.path.join(self.folder_path, img_name)\n",
    "        \n",
    "        # Load grayscale image\n",
    "        X = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n",
    "        X = cv2.resize(X, (self.img_size, self.img_size))\n",
    "        X = X.astype('float32') / 255.0\n",
    "        X = X.reshape(1, self.img_size, self.img_size)  # added channel dim\n",
    "        \n",
    "        # Load color image\n",
    "        y = cv2.imread(img_path)[:, :, ::-1]  # BGR to RGB\n",
    "        y = cv2.resize(y, (self.img_size, self.img_size))\n",
    "        y = y.astype('float32') / 255.0\n",
    "        y = y.transpose(2, 0, 1)  # Change to channel-first format\n",
    "        \n",
    "        return X, y\n",
    "folder_path = r\"/content/celeba_data/img_align_celeba/img_align_celeba\"\n",
    "dataset = CelebADataset(folder_path=folder_path, limit=1000, img_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Get first sample\n",
    "X_sample, y_sample = dataset[0]\n",
    "print(f\"Grayscale image shape: {X_sample.shape}\")\n",
    "print(f\"Color image shape: {y_sample.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(dataset, batch_size=64, shuffle=True)\n",
    "a, b = next(iter(train_loader))\n",
    "a.shape, b.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e570101",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81ca0995",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Autoencoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.Encoder = nn.Sequential(\n",
    "\n",
    "            nn.Conv2d(1, 64, (3,3), stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "\n",
    "            nn.Conv2d(64, 128, (3,3), stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "\n",
    "            nn.Conv2d(128, 256, (3,3), stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "\n",
    "            nn.Conv2d(256, 512, (3,3), stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "\n",
    "            nn.Conv2d(512, 1024, (3,3), stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(1024),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "\n",
    "        )\n",
    "\n",
    "        self.Decoder = nn.Sequential(\n",
    "            nn.ConvTranspose2d(1024, 512, (3,3), stride=2, padding=1, output_padding=1),\n",
    "            nn.ReLU(),\n",
    "\n",
    "            nn.ConvTranspose2d(512, 256, (3,3), stride=2, padding=1, output_padding=1),\n",
    "            nn.ReLU(),\n",
    "\n",
    "            nn.ConvTranspose2d(256, 128, (3,3), stride=2, padding=1, output_padding=1),\n",
    "            nn.ReLU(),\n",
    "\n",
    "            nn.ConvTranspose2d(128, 64, (3,3), stride=2, padding=1, output_padding=1),\n",
    "            nn.ReLU(),\n",
    "\n",
    "            nn.ConvTranspose2d(64, 3, (3,3), stride=2, padding=1, output_padding=1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        x = self.Encoder(x)\n",
    "        x = self.Decoder(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff72b204",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create model and move to GPU\n",
    "model = Autoencoder().to(device)\n",
    "\n",
    "# Loss and optimizer\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f675de2",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 50\n",
    "train_losses = []\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    total_epoch_loss = 0\n",
    "    \n",
    "    for gray, col in tqdm(train_loader):\n",
    "        # Move data to GPU\n",
    "        gray = gray.to(device)\n",
    "        col = col.to(device)\n",
    "        \n",
    "        # Forward pass\n",
    "        outputs = model(gray)\n",
    "        loss = criterion(outputs, col)\n",
    "        \n",
    "        # Backward pass\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        total_epoch_loss += loss.item()\n",
    "    \n",
    "    # Print epoch results\n",
    "    avg_loss = total_epoch_loss / len(train_loader)\n",
    "    print(f\"EPOCH: {epoch+1}, LOSS: {avg_loss}\")\n",
    "    train_losses.append(avg_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "# Plot Loss\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(train_losses, label='Training Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training Loss Over Epochs')\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f793133",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get a batch of data\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    gray, col = next(iter(train_loader))\n",
    "    gray = gray.to(device)\n",
    "    \n",
    "    # Generate predictions\n",
    "    outputs = model(gray)\n",
    "    \n",
    "    # Move back to CPU for visualization\n",
    "    gray = gray.cpu()\n",
    "    outputs = outputs.cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15, 6))\n",
    "num_samples = 5\n",
    "\n",
    "for i in range(num_samples):\n",
    "    # Plot input (grayscale)\n",
    "    plt.subplot(2, num_samples, i + 1)\n",
    "    plt.imshow(gray[i].squeeze(), cmap='gray')\n",
    "    plt.title('Input')\n",
    "    plt.axis('off')\n",
    "    \n",
    "    # Plot output\n",
    "    plt.subplot(2, num_samples, i + 1 + num_samples)\n",
    "    if outputs.shape[1] == 1:  # Grayscale output\n",
    "        plt.imshow(outputs[i].squeeze(), cmap='gray')\n",
    "    else:  # Color output\n",
    "        plt.imshow(outputs[i].permute(1, 2, 0).squeeze())\n",
    "    plt.title('Output')\n",
    "    plt.axis('off')\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
